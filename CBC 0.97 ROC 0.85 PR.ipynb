{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_transaction = pd.read_csv(\"input/train_transaction.csv\",index_col='TransactionID')\n",
    "train_id = pd.read_csv('input/train_identity.csv',index_col='TransactionID')\n",
    "train_transaction = train_transaction.merge(train_id, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ProductCD','card1','card2','card3','card4','card5','card6','addr1','addr2','P_emaildomain','R_emaildomain','M1','M2','M3','M4','M5','M6','M7','M8','M9','DeviceType','DeviceInfo'\n",
    "]\n",
    "category_cols = cols\n",
    "for col in cols:\n",
    "    train_transaction[col].fillna(\"unknown\").astype('category')\n",
    "    train_transaction[col] = LabelEncoder().fit_transform(train_transaction[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id_'+str(x) for x in range(12,39)]\n",
    "category_cols += cols\n",
    "\n",
    "for col in cols:\n",
    "    train_transaction[col].fillna(\"unknown\").astype('category')\n",
    "    train_transaction[col] = LabelEncoder().fit_transform(train_transaction[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ProductCD',\n",
       " 'card1',\n",
       " 'card2',\n",
       " 'card3',\n",
       " 'card4',\n",
       " 'card5',\n",
       " 'card6',\n",
       " 'addr1',\n",
       " 'addr2',\n",
       " 'P_emaildomain',\n",
       " 'R_emaildomain',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'DeviceType',\n",
       " 'DeviceInfo',\n",
       " 'id_12',\n",
       " 'id_13',\n",
       " 'id_14',\n",
       " 'id_15',\n",
       " 'id_16',\n",
       " 'id_17',\n",
       " 'id_18',\n",
       " 'id_19',\n",
       " 'id_20',\n",
       " 'id_21',\n",
       " 'id_22',\n",
       " 'id_23',\n",
       " 'id_24',\n",
       " 'id_25',\n",
       " 'id_26',\n",
       " 'id_27',\n",
       " 'id_28',\n",
       " 'id_29',\n",
       " 'id_30',\n",
       " 'id_31',\n",
       " 'id_32',\n",
       " 'id_33',\n",
       " 'id_34',\n",
       " 'id_35',\n",
       " 'id_36',\n",
       " 'id_37',\n",
       " 'id_38']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove V columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['V'+str(x) for x in range(1,340)]\n",
    "train_transaction_simplified = train_transaction.drop(cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE D COLUMNS\n",
    "for i in range(1,16):\n",
    "    if i in [1,2,3,5,9]: continue\n",
    "    train_transaction_simplified['D'+str(i)] =  train_transaction_simplified['D'+str(i)] - train_transaction_simplified.TransactionDT/np.float32(24*60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove ['D6','D7','D8','D9','D12','D13','D14'] columns - mostly NAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction_simplified = train_transaction_simplified.drop(['D6','D7','D8','D9','D12','D13','D14'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSACTION AMT CENTS\n",
    "train_transaction_simplified['cents'] = (train_transaction_simplified['TransactionAmt'] - np.floor(train_transaction_simplified['TransactionAmt'])).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split train data in train and \"test\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_raw = train_transaction_simplified.drop('isFraud', axis = 1 )\n",
    "y = train_transaction_simplified.isFraud\n",
    "\n",
    "\n",
    "#x_train = x_raw[:3*len(x_raw)//4]\n",
    "#x_test = x_raw[3*len(x_raw)//4:]\n",
    "\n",
    "#y_train = y[:3*len(x_raw)//4]\n",
    "#y_test = y[3*len(x_raw)//4:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sscaler = StandardScaler()\n",
    "x = sscaler.fit_transform(x_raw)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgbClf\n",
    "\n",
    "xgb = xgbClf.XGBClassifier( \n",
    "        n_estimators=2000,\n",
    "        max_depth=12, \n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        missing=-1, \n",
    "        eval_metric='auc',\n",
    "        # USE CPU\n",
    "        #nthread=4,\n",
    "        #tree_method='hist' \n",
    "        # USE GPU\n",
    "        tree_method='gpu_hist' \n",
    "    )\n",
    "xgb.fit(x_train, y_train, \n",
    "        eval_set=[(x_train,y_train)],\n",
    "        verbose=50, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "xgb_pred = xgb.predict(x_test)\n",
    "y_xgb  = xgb.predict_proba(x_test)\n",
    "acc_s_xgb = accuracy_score(y_test, xgb_pred)\n",
    "\n",
    "print (\"Accuracy score XGB: \", acc_s_xgb)\n",
    "\n",
    "curve_xgb   = roc_curve(y_test, y_xgb[:, 1])\n",
    "auc_xgb   = auc(curve_xgb[0], curve_xgb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use CatBoostClassifier for modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98932062, -0.4351738 ,  0.54724983, ..., -0.51925515,\n",
       "        -0.47356535,  1.31426906],\n",
       "       [-1.40506055, -0.39272565, -2.26188683, ...,  2.60248709,\n",
       "        -0.47356535, -0.63911728],\n",
       "       [ 1.69508777,  0.48491261,  0.54724983, ..., -0.51925515,\n",
       "        -0.47356535, -0.87407648],\n",
       "       ...,\n",
       "       [-1.09685993, -0.24671184, -2.26188683, ...,  2.60248709,\n",
       "        -0.47356535, -0.82109548],\n",
       "       [ 0.79274864,  0.81941346,  0.54724983, ..., -0.51925515,\n",
       "        -0.47356535, -0.87407648],\n",
       "       [ 0.04759329, -0.36409237,  0.54724983, ..., -0.51925515,\n",
       "        -0.47356535,  1.31426906]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6923952\tbest: 0.6923952 (0)\ttotal: 485ms\tremaining: 40m 25s\n",
      "500:\ttest: 0.9325845\tbest: 0.9325845 (500)\ttotal: 2m 6s\tremaining: 18m 59s\n",
      "1000:\ttest: 0.9469621\tbest: 0.9469621 (1000)\ttotal: 4m 12s\tremaining: 16m 47s\n",
      "1500:\ttest: 0.9542216\tbest: 0.9542216 (1500)\ttotal: 6m 19s\tremaining: 14m 44s\n",
      "2000:\ttest: 0.9583521\tbest: 0.9583521 (2000)\ttotal: 8m 23s\tremaining: 12m 34s\n",
      "2500:\ttest: 0.9612013\tbest: 0.9612119 (2499)\ttotal: 10m 27s\tremaining: 10m 27s\n",
      "3000:\ttest: 0.9629919\tbest: 0.9629919 (3000)\ttotal: 12m 36s\tremaining: 8m 23s\n",
      "3500:\ttest: 0.9642353\tbest: 0.9642421 (3496)\ttotal: 14m 39s\tremaining: 6m 16s\n",
      "4000:\ttest: 0.9652894\tbest: 0.9652959 (3997)\ttotal: 16m 44s\tremaining: 4m 10s\n",
      "4500:\ttest: 0.9659295\tbest: 0.9659295 (4500)\ttotal: 18m 47s\tremaining: 2m 5s\n",
      "4999:\ttest: 0.9665482\tbest: 0.9665503 (4997)\ttotal: 20m 51s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9665503205\n",
      "bestIteration = 4997\n",
      "\n",
      "Shrink model to first 4998 iterations.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "hyper_params = {\n",
    "    'n_estimators':5000,\n",
    "    'learning_rate': 0.07,\n",
    "    'eval_metric':'AUC',\n",
    "    'loss_function':'Logloss',\n",
    "    'random_seed':42,\n",
    "    'metric_period':500,\n",
    "    'od_wait':500,\n",
    "    'depth': 8\n",
    "} \n",
    "cbc = CatBoostClassifier(**hyper_params)\n",
    "\n",
    "cbc.fit(x_train,y_train,eval_set=(x_test, y_test), use_best_model=True, verbose=True);     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score cat boost classifier:  0.9873054040934286\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "cbc_pred = cbc.predict(x_test)\n",
    "y_cbc  = cbc.predict_proba(x_test)\n",
    "acc_s_cbc = accuracy_score(y_test, cbc_pred)\n",
    "\n",
    "print (\"Accuracy score cat boost classifier: \", acc_s_cbc)\n",
    "\n",
    "curve_cbc   = roc_curve(y_test, y_cbc[:, 1])\n",
    "auc_cbc   = auc(curve_cbc[0], curve_cbc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draw ROC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(curve_cbc[0], curve_cbc[1], label='cbc (area = %0.2f)' % auc_cbc)\n",
    "#plt.plot(curve_xgb[0], curve_xgb[1], label='xgb (area = %0.2f)' % auc_xgb)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve');\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, auc, roc_curve, precision_recall_curve\n",
    "average_precision_cbc = average_precision_score(y_test, y_cbc[:,1])\n",
    "#average_precision_xgb = average_precision_score(y_test, y_xgb[:,1])\n",
    "\n",
    "print('Average precision-recall score CBC: {}'.format(average_precision_cbc))\n",
    "#print('Average precision-recall score XGB: {}'.format(average_precision_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision_cbc, recall_cbc, _ = precision_recall_curve(y_test, y_cbc[:,1])\n",
    "#precision_xgb, recall_xgb, _ = precision_recall_curve(y_test, y_xgb[:,1])\n",
    "\n",
    "\n",
    "plt.plot(recall_cbc, precision_cbc, label='cbc (area = %0.2f)' % average_precision_cbc)\n",
    "#plt.plot(recall_xgb, precision_xgb, label='xgb (area = %0.2f)' % average_precision_xgb)\n",
    "\n",
    "\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('2-class Precision-Recall curve');\n",
    "\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
